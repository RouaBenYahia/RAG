{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNEj+QVpF3bFfF31lyjflBk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RouaBenYahia/RAG/blob/pdf_only_with_mistral/Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "ivVwbEQKjjw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3825f1e0-1177-4489-f198-bb09b0c24650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "TKeQ9tymn8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107fae1d-2fd1-439c-84d0-4544ac718321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/FineTuning-Rag"
      ],
      "metadata": {
        "id": "vNP251hAqkbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e23894f-a1ee-4403-91a2-b1e81b21fea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/FineTuning-Rag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "mcJRUwlUqmOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91814aa0-b790-4c63-f65e-8065abf7d42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.ipynb  Finetuningp1.ipynb  htmltemplate.py\tStreamlit.ipynb\n",
            "app.py\t   Finetuningp2.ipynb  __pycache__\tStreamlit.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/FineTuning-Rag')\n"
      ],
      "metadata": {
        "id": "Wcy4H4IFn9AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit langchain PyPDF2 faiss-cpu tiktoken huggingface-hub\n",
        "!pip install -U langchain_community langchain-huggingface\n"
      ],
      "metadata": {
        "id": "chNpz2xyU0hE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2cc8e4a-0136-4859-96c0-066de20eea5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.69)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.33.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.5)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key=userdata.get('huggingface')\n",
        "from huggingface_hub import login\n",
        "login(token=api_key)\n"
      ],
      "metadata": {
        "id": "IXJ1DWKbU2MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "id": "Rj8OzFwbVBS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e8c863-104f-46cf-88c6-0e8e10530e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K\n",
            "changed 22 packages in 1s\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jOQbWy3UmuPK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVWxIJR5UYvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fc0580-c8d5-4e47-f296-36225f1b6aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Streamlit.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Streamlit.py\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from htmltemplate import css, bot_template, user_template\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "def get_pdf_text(pdf_docs):\n",
        "  text=\"\"\n",
        "  for pdf in pdf_docs:\n",
        "    pdf_reader=PdfReader(pdf)\n",
        "    for page in pdf_reader.pages:\n",
        "      text+=page.extract_text()\n",
        "  return text\n",
        "def get_text_chuncks(text):\n",
        "  text_splitter=CharacterTextSplitter(separator=\"\\n\",chunk_size=1000,chunk_overlap=300,length_function=len)\n",
        "  chunks=text_splitter.split_text(text)\n",
        "  return chunks\n",
        "\n",
        "\n",
        "\n",
        "def get_vectorstore(text_chunks):\n",
        "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={\"device\": \"cpu\"}\n",
        ")\n",
        "\n",
        "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "    return vectorstore\n",
        "\n",
        " #tokenizer = AutoTokenizer.from_pretrained(\"rouabenyahia/FineTuningModel\")\n",
        "    #model = AutoModelForCausalLM.from_pretrained(\"rouabenyahia/FineTuningModel\")\n",
        "def get_conversation_chain(vectorstore):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.0,     # RÃ©ponses dÃ©terministes\n",
        "        do_sample=False\n",
        "    )\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True\n",
        "    )\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "    Tu es un assistant expert. Utilise le contexte ci-dessous pour rÃ©pondre Ã  la question de l'utilisateur.\n",
        "    Si la rÃ©ponse ne se trouve pas dans les documents, dis simplement que tu ne sais pas.\n",
        "\n",
        "    Contexte:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {question}\n",
        "\n",
        "    RÃ©ponse:\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
        "        #retriever=vectorstore.as_retriever(),\n",
        "        memory=memory,\n",
        "        combine_docs_chain_kwargs={\"prompt\": prompt}\n",
        "    )\n",
        "    return conversation_chain\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def handle_userinput(user_question):\n",
        "    retriever = st.session_state.conversation.retriever\n",
        "    docs = retriever.get_relevant_documents(user_question)\n",
        "    st.write(\"ðŸ” Chunks retrouvÃ©s par le retriever:\", len(docs))\n",
        "\n",
        "    if len(docs) == 0:\n",
        "        st.warning(\"âš ï¸ Aucun passage du document nâ€™a Ã©tÃ© trouvÃ© pour cette question. Essayez de reformuler.\")\n",
        "\n",
        "    response = st.session_state.conversation({'question': user_question})\n",
        "    st.session_state.chat_history = response['chat_history']\n",
        "\n",
        "    for i, message in enumerate(st.session_state.chat_history):\n",
        "        content = message.content\n",
        "        if i % 2 == 1:\n",
        "            if \"RÃ©ponse:\" in content:\n",
        "                content = content.split(\"RÃ©ponse:\")[-1].strip()\n",
        "            st.write(bot_template.replace(\"{{MSG}}\", content), unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.write(user_template.replace(\"{{MSG}}\", content), unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Chat with mutiple PDFs\",\n",
        "    page_icon=\":books:\",\n",
        ")\n",
        "\n",
        "st.write(css,unsafe_allow_html=True)\n",
        "\n",
        "if \"conversation\" not in st.session_state:\n",
        "  st.session_state.conversation=None\n",
        "\n",
        "\n",
        "if \"chat_history\" not in st.session_state:\n",
        "  st.session_state.chat_history=None\n",
        "\n",
        "st.header(\"Chat with multiple PDFS : books:\")\n",
        "\n",
        "#user_question=st.text_input(\"Ask a question about your documents\")\n",
        "#if user_question:\n",
        "  #handle_userinput(user_question)\n",
        "\n",
        "user_question = st.text_input(\"Ask a question about your documents\")\n",
        "\n",
        "if user_question and st.session_state.conversation is not None:\n",
        "    handle_userinput(user_question)\n",
        "elif user_question:\n",
        "    st.warning(\"ðŸ“„ Veuillez d'abord uploader vos PDF et cliquer sur 'Process'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with st.sidebar:\n",
        "  st.subheader(\"Your documents\")\n",
        "  pdf_docs=st.file_uploader(\"Upload your PDFs here and click on 'Processs'\",accept_multiple_files=True)\n",
        "  if st.button(\"Process\"):\n",
        "    with st.spinner(\"Processing\"):\n",
        "\n",
        "      raw_text=get_pdf_text(pdf_docs)\n",
        "      if not raw_text.strip():\n",
        "            st.error(\"âš ï¸ Aucun texte nâ€™a Ã©tÃ© extrait du PDF. Le fichier est peut-Ãªtre scannÃ© ou illisible. Veuillez essayer avec un autre PDF.\")\n",
        "            st.stop()\n",
        "      #st.write(raw_text)\n",
        "      text_chunks=get_text_chuncks(raw_text)\n",
        "      #st.write(\"âœ… Nombre de chunks extraits:\", len(text_chunks))\n",
        "\n",
        "      #st.write(text_chunks)\n",
        "      vectorstore = get_vectorstore(text_chunks)\n",
        "\n",
        "      #st.write(vectorstore)\n",
        "      #el conversation chain tawa\n",
        "      # on peut faire Ã§a\n",
        "      st.session_state.conversation=get_conversation_chain(vectorstore)\n",
        "    st.success(\"âœ… The processing of the files is over, you can ask your questions now!\")\n",
        "    #st.session_state.conversation\n",
        "\n",
        "\n",
        "    #get the pdf text\n",
        "    #get the text chuncks\n",
        "    #create the vector store with the embeddings\n",
        "  #juste el api key mtaa hugging face bech nhothaa\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "7PWAYH22qQzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03200e90-31e2-4848-9eee-9f77a79e8727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.ipynb  Finetuningp1.ipynb  htmltemplate.py\tStreamlit.ipynb\n",
            "app.py\t   Finetuningp2.ipynb  __pycache__\tStreamlit.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! wget -q -O - ipv4.icanhazip.com\n",
        "\n"
      ],
      "metadata": {
        "id": "-a38ucOGc1qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632d5be2-f27f-4845-eae1-760afd4e8ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.63.37.141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "! streamlit run Streamlit.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "IMzRX_c6exHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bc1a6a-2559-4101-ccff-b548337556af"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.63.37.141:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kyour url is: https://bitter-feet-lose.loca.lt\n",
            "2025-07-18 09:34:56.175712: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-18 09:34:56.194963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752831296.220087   40462 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752831296.227665   40462 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-18 09:34:56.252393: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import OpenAIEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import OpenAIEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing HuggingFaceInstructEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFaceHub`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFaceHub`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:12: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.vectorstores import FAISS\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.vectorstores import FAISS\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.vectorstores import FAISS\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFacePipeline`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import OpenAIEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import OpenAIEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing HuggingFaceInstructEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:12: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.vectorstores import FAISS\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.vectorstores import FAISS\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.vectorstores import FAISS\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import OpenAIEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import OpenAIEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing HuggingFaceInstructEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:12: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.vectorstores import FAISS\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.vectorstores import FAISS\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.vectorstores import FAISS\n",
            "Loading checkpoint shards: 100% 2/2 [00:03<00:00,  1.67s/it]\n",
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:59: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=pipe)\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:61: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import OpenAIEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import OpenAIEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing HuggingFaceInstructEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFaceHub`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:12: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.vectorstores import FAISS\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.vectorstores import FAISS\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.vectorstores import FAISS\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFacePipeline`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:94: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(user_question)\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:100: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = st.session_state.conversation({'question': user_question})\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import OpenAIEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import OpenAIEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing HuggingFaceInstructEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFaceHub`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:12: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.vectorstores import FAISS\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.vectorstores import FAISS\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.vectorstores import FAISS\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFacePipeline`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing OpenAIEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import OpenAIEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import OpenAIEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:5: LangChainDeprecationWarning: Importing HuggingFaceInstructEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFaceHub`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/drive/MyDrive/FineTuning-Rag/Streamlit.py:12: LangChainDeprecationWarning: Importing FAISS from langchain.vectorstores is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.vectorstores import FAISS\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.vectorstores import FAISS\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here <https://python.langchain.com/docs/versions/v0_2/>\n",
            "  from langchain.vectorstores import FAISS\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import HuggingFacePipeline`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ]
    }
  ]
}